---
title: Monte Carlo Health Attuned Multiple Metrics Evaluation Rubric - preliminary
  tests
author: "Nonie"
date: "09/03/2020"
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(tidyr)
library(dplyr)
library(data.table)
library(magrittr)
library(ggplot2)
library(reshape2)
library(gridExtra)
library(lattice)
library(wesanderson)
library(extrafont)
td_small <- fread('./tp_small.csv', drop = 1)
td_out <- fread('./tp_out.csv')
td_acc <- fread('./tp_acc.csv')
td_pos <- fread('./tp_pos.csv',drop = 1)
td_acru <- fread('./tp_acru.csv',drop = 1)
tp_fin <- fread('./tp_fin.csv', drop = 1)
cols <- c('#453a49','#541388','#d90368','#197278','#c3a995')
grad_cols <- c('#197278', '#776874', '#936473', '#a46375', '#af6476', '#b86878', '#bf6c7b', '#c3727e', '#c77980', '#c98084', '#c98887', '#c9908a', '#c8988e', '#c6a091', '#c3a995')
```
## Introduction 

### Overview
There exist many tools to evaluate clusters resulting from patient subtyping studies, however 
the question is never asked whether the data being clustered actually contains clusters. This 
is an important question as many commenly used clustering methods such as k-means will find 
clusters independent of any cluster structure existing. A method proposed in Pattern Recognition
uses a hypothesis test to test for cluster structure by using a monte carlo simulation of null 
distribution, based on multiple generated data sets which are known to have no underlying cluster 
structure with the parameters of the original data set. 
It compares cluster statistic Q (any appropriate cluster statistic) from the original data set to 
the results of the Q statistic from the monte carlo generated null distribution, and if it is 
above (or below) a pre determined cut off it is determined to have a clustered structure. This 
method could also be used to determine number of clusters.


### Previous Research 
As mentioned above this method is a development of a method outlined in the book Pattern 
Recognition. It has been used in practice in the methods SigClust and M3C 

#### Pattern Recognition 

The method outlined in Pattern Recognition is based on the 
principle of hypothesis testing, in that you can test if data set $X$ 
has cluster structure through testing the following null and alternate hypothesis

__H1__ The data set $X$ does have a cluster structure 

__H0__ The data set $X$ has no cluster structure 

To perform this $X$ has to be compared to a range of data sets which 
we know has no cluster structure to either reject or accept the null hypothesis. 
Monte Carlo simulations which generates randomly dispersed data, known as 'reference data sets'.
These are used to generate the null distribution used to compare the original data to based on 
cluster statistic $Q$. 

The steps involved in the process outlined in Pattern Recognition are outlined below 
and in figure 1. 

1. Generate n number of reference data sets $R$ based on parameters of orignal data set $X$ 
2. Apply a clustering method to $X$ and $R$ 
3. Find the cluster statistic $Q$ for $X$ and $R$ to return $Q_X$ and the set of statistics $Q_R$ 
4. Compare cluster statistc $Q_X$ to set $Q_R$, if it above (or below depending on the nature of $Q$) cut off $p$
the null hypothesis is rejected. If it is the reverse the null hypothesis is accepted. 

It also outlines ways to carry out different parts of the method as follows: 

1. __Generation of data with random distribution__. It states for ratio data that you are testing 
whether the points in $X$ have a random position in hypercube $H_l$ which has $l$ dimentions
where the bounds of those dimentions are the minimum nad maximum value of each varible in $X$. 

To get a random data points should be generated from a uniform distribution in hyoercube $H_1$. 

2. __Cluster Statistic Q__. For non-hierachical concrete (not fuzzy) clustering problems it 
suggests the huberts gamma statistic.

#### Monte Carlo Concensus Clustering (M3C)

__Aim__ M3C uses the monte carlo method outlined above to identify cluster number and detect 
clusters in genome data when using consensus clustering. Consensus clustering is a clustering 
method which is based on stability. It clusters bootstrapped samples of the original data, records 
the frequency of when each point occurs in the same cluster as each other point and then uses the 
resulting matrix as a basis of a dissimilarity matrix for clustering. Senbabaofgly found that this method 
finds clusters in null data sets. They use Proportion of ambiguos pairs (PAC) statistic compared to 
a null distribution to identify the best value of K. However the PAC statistic favours higher values 
of K, so M3C aims to eliminate that bias by turning the comparison to a null distribution into a formal
hypothesis test. 

__Method__ 

1. __Reference Data Set Genertation__. M3C use PCA to extract the eigen vectors of $X$ which are then 
multiplied by a randomly generated dataset from a gaussian distribution 
2. __Cluster Statistic $Q$__. M3C use PAC statistic 
3. __Calculating P value__. M3C uses the following equation to calculate the p value within the bounds 
of the Monte carlo experiment, where $O_k$ is the number of PAC scores in the reference population less than 
or equal to the PAC score of $X$ and $B$ is the total number of simulations. 1 is added to the numerator and 
demonitator so as not to get a p value of 0. 


$$P_K=\frac{O_k + 1}{B+1}$$ 
4. __Calculating P Values Beyond the Monte Carlo Experiment__. M3C fits a beta distribution 
to estimate the p value beyond the ranges of the monte carlo experiment (which has finate number
of simulations). This is because especialy when K = 2, the PAC distribution has a non-normal 
skew and kurtosis. 
5. __Cluster Methods__. M3C uses consencus clustering 

__Tests and Results__ 

1. MC3 compared monte carlo p values with reletive cluster stability index and the real PAC statistic
in two different tests
    + Negative Control (no clusters) simulated data -> was not significant 
    + Positive Control (4 clusters) simulated data -> Significant, all methods found 4 clusters 

    
2. The method was then run on 7 previously clustered datasets to compare results with the method
they used to identify K 
    + They found 2 data sets that did not have cluster structure in the data

3. Running on simulated data with controlled seperation between the data sets
    + M3C using RCSI was found to be the most accurate method 
    + M3C performs equally well compared to others with clusters of low seperation 

__Limitations__

1. M3C does not provide a statistical test for identifying cluster number only comparison 
to null distribution 

2. M3C only looks at consencus clustering and stability 

This method seperates itself from M3C by looking at cluster structure rather than 
stability and being targetted for use on EHR rather than genomics data. 


### Aims 
This is a preliminary investigation to determine the best way to cary out the method. 
These include: 

- Best method for generating a null distribution
- Best statistic for Q 

They have been evaluated by their ability to identify the true number of clusters from 
generated data sets with a known number of clusters with a varied amount of seperation 
between clusters and noise variable


## Method 
### Null Distribution
Three methods were chosen to create null distributions from the original data
![Alt text](./sand_box/test_dists_pics/td2.png)

1. __Shuffle the data__
takes all the original data points and shuffles the order in the
variables to remove correlation between the variables
![Alt text](./sand_box/test_dists_pics/td_rand.png)

2. __Max Min Uniform Distribution__
is generated from a uniform distribution between the minumum and
maximum values of the variable

![Alt text](./sand_box/test_dists_pics/td_minmax.png)

3. __PCA Distribution__
takes the eigan vectures of the data set are gained through PCA, these are
then used to transform a random data set generated from a  single
gaussian distribution. The resulting data set is one with only one
cluster yet maintains the relationships between the variables

![Alt text](./sand_box/test_dists_pics/td_pca.png)

To create a null distribution, 500 test data sets were generated

### Cluster Seperation Metrics
Three Seperation metrics are used:

1. __Huberts Gamma Statistic__
is a measure of how much the high distances
between variables correlates with cluster membership. It uses 2 matrices
the distance matrix which was the basis of clustering (D) and a matrix
recording cluster membership where the value at point (i,j) is 1 if
they are from different clusters and 0 if they are from the same.
The statistic is shown in the equation below, where M is the number of 
pairs, N is the number of observations amd D and C are the matrices 
mentioned above.

$$\Gamma=\frac{1}{M}\sum_{i=1}^{N-1}\sum_{j=i+1}^{N} D(i,j) C(i,j)$$

2. __Normalised Gamma Statistic__
is the normalised version of the statistic above. The normalised statistic 
is shown below where $\mu$ is the mean and $\theta$ is the variance 

$$\hat\Gamma=\frac{\frac{1}{M}\sum_{i=1}^{N-1}\sum_{j=i+1}^{N} \left( D(i,j)-\mu_d\right)(C(i,j)-\mu_c )}{\theta_d\theta_c}$$

3. __Total Within Cluster Sum of Squares__
is the sum of the distances from each point to its assigned cluster
center, the smaller the distance the better.

### Cluster Methodology
We apply k-means to each data set using a k++ initialisation with
50 resamples which then returns the optimum result


### Test Data Generation
The data was generated using SciKit learn Make Classifications function
from the datasets module. 4 parameters of the data are altered we used
a full factorial experimental design:

1. Number of clusters - 2,4,5
2. Number of features - 10,20
3. % Noise features - 0% 10% 50%
4. Seperation (measured in size of hypercube between clusters) - 0.5,1,3

This resulted in 54 distinct data sets.

### Overall Experiment Structure

1. 54 Datasets were created
2. For each data set 500 null distributions were made with each null
distribution method (total 1500 null distributions
3. K-means was run on the original data set and 1500 null datasets
and the three cluster seperation metrics were returned, for k = 2-6
4. The mean and standard deviation is returned for each null distribution
method, for each seperation metric and for each cluster number
5. The seperation metric score and p value for the original data set
is returned for each null distribution method, for each seperation 
metric and for each cluster number

### Experiment Outcomes

Each distribution method and Cluster metric will by the accuracy of 
identifying the correct cluster number 



```{r plots, echo = FALSE}
 
td_sense <- td_small %>% select('both','Sense','tp','fn') %>% gather(key = 'type', value = 'value', tp,fn)%>% 
  mutate(Sense = round(Sense,2))
td_spec <- td_small %>% select('both','Spec','tn','fp') %>% gather(key = 'type', value = 'value', tn,fp)
tp_bar <- ggplot(data = td_sense, aes(x = both, y = value, fill = type)) + 
    geom_bar(stat = 'identity', position = 'identity', alpha = .5) + 
    theme_minimal()+ 
    geom_text(data = td_sense %>% filter(type == 'fn'), aes(label = Sense), y = 30) + 
    labs(title = 'Method Sensitivity', x = 'Method', y = '') +
    theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
    scale_fill_manual(name = "", labels = c("False Negative", "True Positive"), values = cols)
    
    
tp_fin2 <- tp_fin %>% mutate_all(factor)
tp_fin2$sep <- factor(tp_fin2$sep, levels(tp_fin2$sep)[c(3,2,1)])

success_wrap = ggplot(tp_fin2, aes(noise, sep,fill = only)) + geom_tile()+ theme_minimal()
success_wrap = success_wrap + facet_grid(mc_type ~ index) + 
  labs(title = 'Correctly Identified Cluster Numbers per Method', x = 'Noise Ratio', y = 'Seperation') + 
  scale_fill_manual(name = ' Number\n Identified',values = cols)


sums_wrap <- ggplot(tp_fin2, aes(noise, sep,fill = Sums)) + geom_tile()+ theme_minimal()
sums_wrap = sums_wrap + facet_grid(mc_type ~ index) + 
  labs(title = 'Total Identified Cluster Numbers per Method', x = 'Noise Ratio', y = 'Seperation') + 
  scale_fill_manual(name = ' Number\n Identified', values = grad_cols)

lower_4 <- function(x){
   thing <- quantile(x)
   return(unname(thing[1]))
}

upper_4 <- function(x){
   thing <- quantile(x)
   return(unname(thing[4]))
}

tp_km <- td_acru %>% 
  mutate(Total = replace_na(Total, 0)) %>% 
  group_by(Total,index) %>% 
  summarise(mean = mean(acru),lower = lower_4(acru), upper = upper_4(acru))%>% 
  mutate(Total2 = ifelse(Total == '1','Yes','No'))

tp_km$Total <- factor(tp_km$Total)  

  
km_plot <- ggplot(tp_km, aes(x = Total2, y = mean, fill = index)) + 
  geom_bar(stat = 'identity', position = 'dodge') +
  geom_errorbar(aes(ymin = lower, ymax = upper), position = position_dodge(0.9),width = .1, color = 'dark grey')+
  theme_minimal()+ 
  labs(title = 'K Means Accuracy per Method Accuracy', x = 'Cluster Number Discovered', y = 'K Means Accuracy')+
  scale_fill_manual(values = cols)
```

# Results 

Figure 1 shows the senstivity for each metric, null distribution combination. The 
first thing to note is that using the within sum of squares was unsuccsesfull 
no matter what the distribution method used. The best method used was the combination 
of random order generation and huberts gamma statistic with a sensitivity of .5 which 
is still pretty bad. Overall out of the data genration methods random order performed 
the best, follewed by pca then lastly min max. 


```{r figure 1,echo = F}
plot(tp_bar)

```

Figure 2 shows how many times each method distribution pairing identified the correct
cluster number and did not identify any other cluster number as significant, broken 
down by seperation and ratio of noise varabibles (max 3). As the ratio of noise variables 
increasesand the seperation value decreases (top right of each figure) the clustering 
problem gets harder. 

```{r figure 2,echo = F}
plot(success_wrap)

```

Figure 2 shows huberts gamma statistic performs better than the other 2 metrics and 
shows a split between random order being better at identifying the harder cluster
problems  with smaller seperation, and pca better at solving the easier ones. This 
could be because if there a large seperation in the data already there will also 
be in the null distribution as it only uses the values that exist. 

Figure 3 shows how many times the method, distributer pairing thought there were 
clusters there (for k = 2 -6). What it shows is within cluster sum of squares unable 
to desern between clustered and null distributions whatsoever, however the issue 
with hubers random order and norm min max seem that it is finds clusters when they
are not there. 


```{r figure 3, echo = F}
plot(sums_wrap)

```
One potential reason for the methods not finding hte correct cluster number is 
that k-means did a terrible job of identifying the clusters, so we compared 
the mean matching score between the k means cluster labels and the original cluster. 
This is shown in figure 4. It appears from this plot that k-means is partly responsible
for not being able to identify the correct cluster number 


```{r figure 4, echo = F}
plot(km_plot)

```

# Going Forward 

1. Use PCA before K-means with greater number of random starts to improve performance 
2. Test more cluster metrics (drop tss)
3. Return metrics on the distributions namely kertosis 

